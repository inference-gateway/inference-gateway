==> Linting ../charts/inference-gateway
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed
---
# Source: inference-gateway/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: inference-gateway/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: inference-gateway
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
---
# Source: inference-gateway/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-gateway
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
data:
  ANTHROPIC_API_URL: "https://api.anthropic.com/v1"
  APPLICATION_NAME: "inference-gateway"
  CLIENT_IDLE_CONN_TIMEOUT: "30s"
  CLIENT_MAX_IDLE_CONNS: "20"
  CLIENT_MAX_IDLE_CONNS_PER_HOST: "20"
  CLIENT_TIMEOUT: "30s"
  CLIENT_TLS_MIN_VERSION: "TLS12"
  CLOUDFLARE_API_URL: "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai"
  COHERE_API_URL: "https://api.cohere.ai"
  DEEPSEEK_API_URL: "https://api.deepseek.com"
  ENABLE_AUTH: "false"
  ENABLE_TELEMETRY: "false"
  ENVIRONMENT: "production"
  GROQ_API_URL: "https://api.groq.com/openai/v1"
  OIDC_ISSUER_URL: "http://keycloak:8080/realms/inference-gateway-realm"
  OLLAMA_API_URL: "http://ollama.ollama.svc:8080/v1"
  OPENAI_API_URL: "https://api.openai.com/v1"
  SERVER_HOST: "0.0.0.0"
  SERVER_IDLE_TIMEOUT: "120s"
  SERVER_PORT: "8080"
  SERVER_READ_TIMEOUT: "30s"
  SERVER_TLS_CERT_PATH: ""
  SERVER_TLS_KEY_PATH: ""
  SERVER_WRITE_TIMEOUT: "30s"
---
# Source: inference-gateway/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["configmaps", "secrets"]
    verbs: ["get", "watch", "list"]
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "list", "watch"]
---
# Source: inference-gateway/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ig
subjects:
  - kind: ServiceAccount
    name: ig
    namespace: default
---
# Source: inference-gateway/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
---
# Source: inference-gateway/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: inference-gateway
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        helm.sh/chart: inference-gateway-0.1.0
        app.kubernetes.io/name: inference-gateway
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.4.1"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: ig
      containers:
        - name: inference-gateway
          image: "ghcr.io/inference-gateway/inference-gateway:v0.4.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          envFrom:
            - configMapRef:
                name: inference-gateway
            - secretRef:
                name: inference-gateway
---
# Source: inference-gateway/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ig
  labels:
    helm.sh/chart: inference-gateway-0.1.0
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ig
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 80
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    - type: External
      external:
        metric:
          name: requests_per_second
          selector:
            matchLabels:
              app: ig
        target:
          type: AverageValue
          averageValue: 100
